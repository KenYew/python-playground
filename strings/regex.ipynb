{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸŸ¨ Amazon SDE Regex Question\n",
    "Find user with lowest latency from log file \"200,John,/home,60ms 200,Sarah,/log,13ms 500,Jack,/home,40ms\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sarah 13\n",
      "Jack 40\n",
      "John 60\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "hashMap = {}\n",
    "result = []\n",
    "\n",
    "log = \"200,John,/home,60ms 200,Sarah,/log,13ms 500,Jack,/home,40ms \"\n",
    "regex = r'(?P<number>\\d+),(?P<name>\\w+),/(?P<directory>\\w+),(?P<latency>\\d+)ms\\s'\n",
    "tuples = re.findall(regex, log)\n",
    "\n",
    "for tuple in tuples:\n",
    "    (number, name, directory, latency) = tuple\n",
    "    if name not in hashMap: \n",
    "        hashMap[latency] = name\n",
    "\n",
    "sortedLatencies = sorted(hashMap.keys())\n",
    "for latency in sortedLatencies:\n",
    "    result.append(f'{hashMap[latency]} {latency}')\n",
    "\n",
    "print('\\n'.join(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸŸ¨ [Baby Names (Google Regex Exercise)](https://developers.google.com/edu/python/exercises/baby-names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1990\n",
      "Amanda 4\n",
      "Andrew 7\n",
      "Ashley 2\n",
      "Brittany 3\n",
      "Christopher 2\n",
      "Daniel 5\n",
      "David 6\n",
      "Elizabeth 9\n",
      "Emily 12\n",
      "James 8\n",
      "Jennifer 8\n",
      "Jessica 1\n",
      "John 12\n",
      "Joseph 10\n",
      "Joshua 4\n",
      "Justin 9\n",
      "Lauren 10\n",
      "Matthew 3\n",
      "Megan 11\n",
      "Michael 1\n",
      "Ryan 11\n",
      "Samantha 5\n",
      "Sarah 6\n",
      "Stephanie 7\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "log = \"\"\"\n",
    "<h3 align=\"center\">Popularity in 1990</h3>\n",
    "<p align=\"center\">\n",
    "<table width=\"48%\" border=\"1\" bordercolor=\"#aaabbb\"\n",
    " cellpadding=\"2\" cellspacing=\"0\" summary=\"Popularity for top 1000\">\n",
    "<tr align=\"center\" valign=\"bottom\">\n",
    "  <th scope=\"col\" width=\"12%\" bgcolor=\"#efefef\">Rank</th>\n",
    "  <th scope=\"col\" width=\"41%\" bgcolor=\"#99ccff\">Male name</th>\n",
    "<th scope=\"col\" bgcolor=\"pink\" width=\"41%\">Female name</th></tr>\n",
    "<tr align=\"right\"><td>1</td><td>Michael</td><td>Jessica</td>\n",
    "<tr align=\"right\"><td>2</td><td>Christopher</td><td>Ashley</td>\n",
    "<tr align=\"right\"><td>3</td><td>Matthew</td><td>Brittany</td>\n",
    "<tr align=\"right\"><td>4</td><td>Joshua</td><td>Amanda</td>\n",
    "<tr align=\"right\"><td>5</td><td>Daniel</td><td>Samantha</td>\n",
    "<tr align=\"right\"><td>6</td><td>David</td><td>Sarah</td>\n",
    "<tr align=\"right\"><td>7</td><td>Andrew</td><td>Stephanie</td>\n",
    "<tr align=\"right\"><td>8</td><td>James</td><td>Jennifer</td>\n",
    "<tr align=\"right\"><td>9</td><td>Justin</td><td>Elizabeth</td>\n",
    "<tr align=\"right\"><td>10</td><td>Joseph</td><td>Lauren</td>\n",
    "<tr align=\"right\"><td>11</td><td>Ryan</td><td>Megan</td>\n",
    "<tr align=\"right\"><td>12</td><td>John</td><td>Emily</td>\n",
    "\"\"\"\n",
    "def extractNames(log):\n",
    "  names = []\n",
    "  yearMatch = re.search(r'Popularity\\sin\\s(?P<year>\\d{4})', log)\n",
    "  if not yearMatch:\n",
    "    print(\"Invalid Input: Couldn't find the year!\")\n",
    "  year = yearMatch.group('year')\n",
    "  names.append(year)\n",
    "  tuples = re.findall(r'<tr align=\"right\"><td>(?P<rank>\\d+)</td><td>(?P<boyName>\\w+)</td><td>(?P<girlName>\\w+)</td>', log)\n",
    "\n",
    "  namesToRank = {}\n",
    "  for tuple in tuples:\n",
    "    (rank, boyName, girlName) = tuple\n",
    "    if boyName not in namesToRank: \n",
    "      namesToRank[boyName] = rank\n",
    "    if girlName not in namesToRank: \n",
    "      namesToRank[girlName] = rank\n",
    "\n",
    "  sortedNames = sorted(namesToRank.keys())\n",
    "  for name in sortedNames: \n",
    "    names.append(f'{name} {namesToRank[name]}')\n",
    "\n",
    "  return names\n",
    "\n",
    "def main():\n",
    "  print('\\n'.join(extractNames(log)))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸŸ¨ [Log Puzzle (Google Regex Exercise)](https://developers.google.com/edu/python/exercises/log-puzzle)\n",
    "Given an apache logfile, find the puzzle urls and download the images.\n",
    "Here's what a puzzle url looks like:\n",
    "```python\n",
    "10.254.254.28 - - [06/Aug/2007:00:12:20 -0700] \"GET /keyser/22300/ HTTP/1.0\" 302 528 \"-\" \"Mozilla/5.0 (X11; U; Linux i686 (x86_64); en-US; rv:1.8.1.4) Gecko/20070515 Firefox/2.0.0.4\"\n",
    "10.254.254.58 - - [06/Aug/2007:00:10:05 -0700] \"GET /edu/languages/google-python-class/images/puzzle/a-baaa.jpg HTTP/1.0\" 200 2309 \"-\" \"googlebot-mscrawl-moma (enterprise; bar-XYZ; foo123@google.com,foo123@google.com,foo123@google.com,foo123@google.com)\"\n",
    "10.254.254.28 - - [06/Aug/2007:00:11:08 -0700] \"GET /favicon.ico HTTP/1.0\" 302 3404 \"-\" \"googlebot-mscrawl-moma (enterprise; bar-XYZ; foo123@google.com,foo123@google.com,foo123@google.com,foo123@google.com)\"\n",
    "10.254.254.29 - - [06/Aug/2007:00:13:48 -0700] \"GET /edu/languages/google-python-class/images/puzzle/a-baag.jpg HTTP/1.0\" 302 3404 \"-\" \"googlebot-mscrawl-moma (enterprise; bar-XYZ; foo123@google.com)\"\n",
    "10.1.40.113 - - [06/Aug/2007:00:11:14 -0700] \"GET /keyser/24708/ HTTP/1.0\" 200 5694 \"-\" \"googlebot-mscrawl-moma (enterprise; bar-XYZ; foo123@google.com,foo123@google.com,foo123@google.com,foo123@google.com)\"\n",
    "10.254.254.57 - - [06/Aug/2007:00:13:39 -0700] \"GET /keyser/24354/ HTTP/1.0\" 404 3404 \"-\" \"Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.8.1.6) Gecko/20070725 Firefox/2.0.0.6\"\n",
    "10.254.254.29 - - [06/Aug/2007:00:05:29 -0700] \"GET /keyser/2391/ HTTP/1.0\" 302 6267 \"-\" \"googlebot-mscrawl-moma (enterprise; bar-XYZ; foo123@google.com,foo123@google.com,foo123@google.com,foo123@google.com)\"\n",
    "10.254.254.138 - - [06/Aug/2007:00:13:48 -0700] \"GET /edu/languages/google-python-class/images/puzzle/a-baac.jpg HTTP/1.0\" 200 4284 \"-\" \"Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.8.1.6; Google-TR-5.1.707.6657-en) Gecko/20070725 Firefox/2.0.0.6\"\n",
    "10.254.254.57 - - [06/Aug/2007:00:12:18 -0700] \"GET /edu/languages/google-python-class/images/puzzle/a-baac.jpg HTTP/1.0\" 404 10496 \"-\" \"googlebot-mscrawl-moma (enterprise; bar-XYZ; foo123@google.com,foo123@google.com,foo123@google.com,foo123@google.com)\"\n",
    "10.254.254.28 - - [06/Aug/2007:00:14:24 -0700] \"GET /keyser/22139/ HTTP/1.0\" 200 528 \"-\" \"googlebot-mscrawl-moma (enterprise; bar-XYZ; foo123@google.com,foo123@google.com,foo123@google.com,foo123@google.com)\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# Sort the urls in increasing order by 2nd word if present\n",
    "def url_sort_key(url):\n",
    "  # 10.254.254.28 - - [06/Aug/2007:00:13:48 -0700] \"GET /~foo/puzzle-bar-aaab.jpg HTTP/1.0\" 302 528 \"-\" \"Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.8.1.6) Gecko/20070725 Firefox/2.0.0.6\"\n",
    "  match = re.search(r'-(\\w+)-(\\w+)\\.\\w+', url)\n",
    "  if match:\n",
    "    return match.group(2)\n",
    "  else:\n",
    "    return url\n",
    "  \n",
    "# Returns a list of the puzzle urls from the given log file, extracting the hostname from the filename itself.\n",
    "# Screens out duplicate urls and returns the urls sorted into increasing order.\n",
    "def read_urls(filename):\n",
    "  # Extract the hostname from the filename\n",
    "  underbar = filename.index('_')\n",
    "  host = filename[underbar + 1:]\n",
    "  # Store the urls into a dict to screen out the duplicates\n",
    "  url_dict = {}\n",
    "  f = open(filename)\n",
    "  for line in f:\n",
    "    # Find the path which is after the GET and surrounded by spaces.\n",
    "    match = re.search(r'\"GET (\\S+)', line)\n",
    "    if match:\n",
    "      path = match.group(1)\n",
    "      # Add to dict if it's a special \"puzzle\" url (could combine this 'puzzle' check with the above GET extraction)\n",
    "      if 'puzzle' in path:\n",
    "        url_dict['http://' + host + path] = 1\n",
    "  return sorted(url_dict.keys(), key=url_sort_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸŸ© Parse Apache Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = \"\"\"\n",
    "10.254.254.28 - - [06/Aug/2007:00:12:20 -0700] \"GET /keyser/22300/ HTTP/1.0\" 302 528 \"-\" \"Mozilla/5.0 (X11; U; Linux i686 (x86_64); en-US; rv:1.8.1.4) Gecko/20070515 Firefox/2.0.0.4\"\n",
    "10.254.254.58 - - [06/Aug/2007:00:10:05 -0700] \"GET /edu/languages/google-python-class/images/puzzle/a-baaa.jpg HTTP/1.0\" 200 2309 \"-\" \"googlebot-mscrawl-moma (enterprise; bar-XYZ; foo123@google.com,foo123@google.com,foo123@google.com,foo123@google.com)\"\n",
    "10.254.254.28 - - [06/Aug/2007:00:11:08 -0700] \"GET /favicon.ico HTTP/1.0\" 302 3404 \"-\" \"googlebot-mscrawl-moma (enterprise; bar-XYZ; foo123@google.com,foo123@google.com,foo123@google.com,foo123@google.com)\"\n",
    "10.254.254.29 - - [06/Aug/2007:00:13:48 -0700] \"GET /edu/languages/google-python-class/images/puzzle/a-baag.jpg HTTP/1.0\" 302 3404 \"-\" \"googlebot-mscrawl-moma (enterprise; bar-XYZ; foo123@google.com)\"\n",
    "10.1.40.113 - - [06/Aug/2007:00:11:14 -0700] \"GET /keyser/24708/ HTTP/1.0\" 200 5694 \"-\" \"googlebot-mscrawl-moma (enterprise; bar-XYZ; foo123@google.com,foo123@google.com,foo123@google.com,foo123@google.com)\"\n",
    "10.254.254.57 - - [06/Aug/2007:00:13:39 -0700] \"GET /keyser/24354/ HTTP/1.0\" 404 3404 \"-\" \"Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.8.1.6) Gecko/20070725 Firefox/2.0.0.6\"\n",
    "10.254.254.29 - - [06/Aug/2007:00:05:29 -0700] \"GET /keyser/2391/ HTTP/1.0\" 302 6267 \"-\" \"googlebot-mscrawl-moma (enterprise; bar-XYZ; foo123@google.com,foo123@google.com,foo123@google.com,foo123@google.com)\"\n",
    "10.254.254.138 - - [06/Aug/2007:00:13:48 -0700] \"GET /edu/languages/google-python-class/images/puzzle/a-baac.jpg HTTP/1.0\" 200 4284 \"-\" \"Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.8.1.6; Google-TR-5.1.707.6657-en) Gecko/20070725 Firefox/2.0.0.6\"\n",
    "10.254.254.57 - - [06/Aug/2007:00:12:18 -0700] \"GET /edu/languages/google-python-class/images/puzzle/a-baac.jpg HTTP/1.0\" 404 10496 \"-\" \"googlebot-mscrawl-moma (enterprise; bar-XYZ; foo123@google.com,foo123@google.com,foo123@google.com,foo123@google.com)\"\n",
    "10.254.254.28 - - [06/Aug/2007:00:14:24 -0700] \"GET /keyser/22139/ HTTP/1.0\" 200 528 \"-\" \"googlebot-mscrawl-moma (enterprise; bar-XYZ; foo123@google.com,foo123@google.com,foo123@google.com,foo123@google.com)\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pythex.org to form regular expression\n",
    "import re\n",
    "regex = r'(?P<ip>\\d+\\.\\d+\\.\\d+\\.\\d+) - - \\[(?P<date>\\S+\\s\\S+)\\]\\s\\SGET\\s(?P<url>\\S+)'\n",
    "tuples = re.findall(regex, logs)\n",
    "ips, dates, urls = [], [], []\n",
    "ipFrequency, dateFrequency, urlFrequency = {}, {}, {} \n",
    "\n",
    "for tuple in tuples: \n",
    "  ip, date, url = tuple\n",
    "\n",
    "  ips.append(ip)\n",
    "  if ip not in ipFrequency: \n",
    "    ipFrequency[ip] = 0\n",
    "  ipFrequency[ip] += 1\n",
    "\n",
    "  dates.append(date)\n",
    "  if date not in dateFrequency: \n",
    "    dateFrequency[date] = 0\n",
    "  dateFrequency[date] += 1\n",
    "\n",
    "  urls.append(url)\n",
    "  if url not in urlFrequency: \n",
    "    urlFrequency[url] = 0\n",
    "  urlFrequency[url] += 1\n",
    "\n",
    "## Sort dictionaries by their values (e.g: frequency)\n",
    "# Use: x[0] to sort by key, x[1] to sort by value, reverse=False for increasing order, reverse=True for decreasing order\n",
    "increasingIpFrequency = sorted(ipFrequency.items(), key=lambda x : x[1])\n",
    "decreasingIpFrequency = sorted(ipFrequency.items(), key=lambda x : x[1], reverse=True)\n",
    "increasingDateFrequency = sorted(dateFrequency.items(), key=lambda x : x[1])\n",
    "decreasingDateFrequency = sorted(dateFrequency.items(), key=lambda x : x[1], reverse=True)\n",
    "increasingUrlFrequency = sorted(urlFrequency.items(), key=lambda x : x[1])\n",
    "decreasingUrlFrequency = sorted(urlFrequency.items(), key=lambda x : x[1], reverse=True)\n",
    "print(f'increasingIpFrequency: {increasingIpFrequency}')\n",
    "print(f'decreasingIpFrequency: {decreasingIpFrequency}')\n",
    "print(f'increasingDateFrequency: {increasingDateFrequency}')\n",
    "print(f'decreasingDateFrequency: {decreasingDateFrequency}')\n",
    "print(f'increasingUrlFrequency: {increasingUrlFrequency}')\n",
    "print(f'decreasingUrlFrequency: {decreasingUrlFrequency}')\n",
    "\n",
    "## Obtain the key with the highest value\n",
    "print('\\n')\n",
    "print(f'Max ip: {max(ipFrequency, key=ipFrequency.get)}')\n",
    "print(f'Frequency: {max(ipFrequency.values())}\\n')\n",
    "print(f'Max date: {max(dateFrequency, key=dateFrequency.get)}')\n",
    "print(f'Frequency: {max(dateFrequency.values())}\\n')\n",
    "print(f'Max url: {max(urlFrequency, key=urlFrequency.get)}')\n",
    "print(f'Frequency: {max(urlFrequency.values())}')\n",
    "\n",
    "## Obtain the key with the lowest value\n",
    "print('\\n')\n",
    "print(f'Min ip: {min(ipFrequency, key=ipFrequency.get)}')\n",
    "print(f'Frequency: {min(ipFrequency.values())}\\n')\n",
    "print(f'Min date: {min(dateFrequency, key=dateFrequency.get)}')\n",
    "print(f'Frequency: {min(dateFrequency.values())}\\n')\n",
    "print(f'Min url: {min(urlFrequency, key=urlFrequency.get)}')\n",
    "print(f'Frequency: {min(urlFrequency.values())}')\n",
    "\n",
    "## Print a list of sorted extracted data\n",
    "print('\\nList of ips:')\n",
    "print(\"\\n\".join(sorted(ips)))\n",
    "print('\\nList of dates:')\n",
    "print(\"\\n\".join(sorted(dates)))\n",
    "print('\\nList of urls:')\n",
    "print(\"\\n\".join(sorted(urls)))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
